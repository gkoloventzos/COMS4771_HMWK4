\section*{Problem 1}
The EM algorithm for multinomial distributions is similar to the Gaussian ones.
I will use the steps that are also depicted in Bishop's book in chapter 9 for
Gaussian.
\begin{align*}
p(x) = \sum_{k=1}^K \pi_k p(x \mid \mu_k)
\end{align*}
also
\begin{align*}
\pi_k p(x \mid \mu_k) = \prod_{j=1}^M \mu_k (j)^{x(j)}
\end{align*}
The $z$ values (mixing coeffient) of having the same properties of Gaussian mixtures.
So the $p( z_k = 1) = \pi_k$ for which $\sum_{k=1}^k \pi_k = 1$
The marginal distribution $p(z)$ can be written as:
\begin{align*}
p(z) = \sum_{k=1}^K \pi_{k}^(z_k)
\end{align*}
and
\begin{align*}
p(x_j =1 \mid z=k) = p(x\mid z=k) \mu_l
\end{align*}
Using this equations we have 
\begin{align*}
p(x\mid z) = \prod_{k=1}^K (\mu_{k})^ z_{k}
\end{align*}
So combining all these:
$p(x) = \sum_{k=1}^K p(z)p(x\mid z) = \sum_{k=1}^K \pi_k \mu_k$
\subsection*{E-step}
For the E step we have to calculate the $t_nj$ as we see in the problem statement.
By Bayes' Rule we have
$t_nj=p(z_n =j \mid x_n,\theta) = p(z_n =j)p(x\mid z_n,\theta)$
if we plug the densities we already have:
\begin{align*}
p(z_n =j \mid x_n,\theta) = \frac{\pi_j \cdot \mu_j}{\sum_{l=1}^K \pi_l \mu_l}
\end{align*}
\subsection*{M-step}
Using the $t$ from E-step we will re-calculate our model $\theta$.
$t_nj=\frac{\pi_j \cdot \mu_j}{\sum_{l=1}^K \pi_l \mu_l}$
So $\theta_j = \frac{\sum_{i=1}^n x_{i} t_i}{M\sum_{i=1}^n t_{i}}$.


